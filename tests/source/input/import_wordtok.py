from nltk import word_tokenize

tokenizer = word_tokenize
